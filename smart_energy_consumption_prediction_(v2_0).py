# -*- coding: utf-8 -*-
"""Smart energy consumption prediction (V2.0).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/161vH76bGQ8mm6-GKc2sxSon48qMBXSwx
"""

# ============================================================
# SMART ENERGY CONSUMPTION FORECASTING (Bidirectional LSTM)
# ============================================================

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# ------------------------------------------------------------
#LOAD AND FIX CSV
# ------------------------------------------------------------
df = pd.read_csv("data/household_power_consumption.csv", sep=None, engine="python")
print("Columns before fix:", df.columns.tolist())

# Handle combined header if necessary
if len(df.columns) == 1:
    df = df[df.columns[0]].str.split(',', expand=True)
    df.columns = [
        'index','Date','Time','Global_active_power','Global_reactive_power',
        'Voltage','Global_intensity','Sub_metering_1','Sub_metering_2','Sub_metering_3'
    ]

df = df.drop(columns=['index'], errors='ignore')

# Clean numeric columns
df.replace('?', pd.NA, inplace=True)
for col in df.columns:
    if col not in ['Date', 'Time']:
        df[col] = pd.to_numeric(df[col], errors='coerce')

# Create datetime
df['datetime'] = pd.to_datetime(df['Date'] + ' ' + df['Time'], format='%d/%m/%Y %H:%M:%S', errors='coerce')
df.sort_values('datetime', inplace=True)
df.set_index('datetime', inplace=True)
df.dropna(inplace=True)
df = df.drop(columns=['Date', 'Time'], errors='ignore')

# ------------------------------------------------------------
#RESAMPLE HOURLY + FEATURE ENGINEERING
# ------------------------------------------------------------
df_hourly = df.resample('H').mean()
df_hourly.dropna(inplace=True)

df_hourly['hour'] = df_hourly.index.hour
df_hourly['day_of_week'] = df_hourly.index.dayofweek
df_hourly['is_weekend'] = (df_hourly['day_of_week'] >= 5).astype(int)

# ------------------------------------------------------------
#FEATURE SELECTION
# ------------------------------------------------------------
features = [
    'Global_active_power', 'Global_reactive_power', 'Voltage',
    'Global_intensity', 'Sub_metering_1', 'Sub_metering_2', 'Sub_metering_3',
    'hour', 'day_of_week', 'is_weekend'
]

data = df_hourly[features].values
data = data[~np.isnan(data).any(axis=1)]

# ------------------------------------------------------------
#SCALING
# ------------------------------------------------------------
scaler = MinMaxScaler()
data_scaled = scaler.fit_transform(data)

# ------------------------------------------------------------
#CREATE SEQUENCES (7-day lookback = 168 hours)
# ------------------------------------------------------------
def create_sequences(data, seq_length=168):
    X, y = [], []
    for i in range(len(data) - seq_length):
        X.append(data[i:i+seq_length])
        y.append(data[i+seq_length, 0])  # Predicting Global_active_power
    return np.array(X), np.array(y)

X, y = create_sequences(data_scaled)
split = int(0.8 * len(X))
X_train, X_test, y_train, y_test = X[:split], X[split:], y[:split], y[split:]
print(f"Train shape: {X_train.shape}, Test shape: {X_test.shape}")

# ------------------------------------------------------------
#BUILD BIDIRECTIONAL LSTM MODEL
# ------------------------------------------------------------
model = Sequential([
    Bidirectional(LSTM(128, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2]))),
    Dropout(0.2),
    LSTM(64),
    Dense(32, activation='relu'),
    Dense(1)
])

model.compile(optimizer='adam', loss='mse')

# ------------------------------------------------------------
#TRAIN WITH EARLY STOPPING
# ------------------------------------------------------------
es = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)
history = model.fit(
    X_train, y_train,
    epochs=60,
    batch_size=32,
    validation_data=(X_test, y_test),
    callbacks=[es],
    verbose=1
)

# ------------------------------------------------------------
#EVALUATE MODEL
# ------------------------------------------------------------
y_pred = model.predict(X_test)

mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print("\nModel Evaluation Metrics:")
print(f"MSE  : {mse:.6f}")
print(f"RMSE : {rmse:.6f}")
print(f"MAE  : {mae:.6f}")
print(f"R²   : {r2:.4f}  (1.0 = perfect fit)")
print(f"Approximate Model Accuracy: {r2 * 100:.2f}%")

# ------------------------------------------------------------
#PLOTS
# ------------------------------------------------------------
# Loss curves
plt.figure(figsize=(10,4))
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.legend()
plt.title("Training & Validation Loss (Bidirectional LSTM)")
plt.xlabel("Epochs")
plt.ylabel("MSE")
plt.show()

# Prediction vs True
plt.figure(figsize=(10,4))
plt.plot(y_test[:200], label='True')
plt.plot(y_pred[:200], label='Predicted')
plt.legend()
plt.title("Smart Energy Consumption Prediction (Bidirectional LSTM)")
plt.show()

# ------------------------------------------------------------
#FUTURE FORECASTING (NEXT 24 HOURS)
# ------------------------------------------------------------
# Start with the last sequence from the dataset
last_sequence = data_scaled[-168:]
future_predictions = []

for _ in range(24):  # predict next 24 hours
    input_seq = last_sequence[-168:].reshape(1, 168, X.shape[2])
    next_pred = model.predict(input_seq)
    # Append prediction (and dummy zeros for other features)
    new_entry = np.zeros((1, X.shape[2]))
    new_entry[0, 0] = next_pred  # predicted active power
    last_sequence = np.vstack([last_sequence, new_entry])
    future_predictions.append(next_pred[0, 0])

# Inverse scale predicted values
future_predictions = np.array(future_predictions).reshape(-1, 1)
dummy = np.zeros((len(future_predictions), data_scaled.shape[1]))
dummy[:, 0] = future_predictions[:, 0]
future_predictions_real = scaler.inverse_transform(dummy)[:, 0]

# ------------------------------------------------------------
#VISUALIZE FUTURE FORECAST
# ------------------------------------------------------------
plt.figure(figsize=(10,4))
plt.plot(future_predictions_real, marker='o')
plt.title("Forecasted Energy Consumption for Next 24 Hours")
plt.xlabel("Future Hour")
plt.ylabel("Global Active Power (kW)")
plt.grid(True)
plt.show()

# ------------------------------------------------------------
#SAVE MODEL
# ------------------------------------------------------------
model.save("smart_energy_forecast_model.h5")
print("\n✅ Model saved as 'smart_energy_forecast_model.h5'")

# ============================================================
# SMART ENERGY CONSUMPTION FORECASTING (CNN + LSTM Hybrid)
# ============================================================

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout, Conv1D, MaxPooling1D, Flatten
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# ------------------------------------------------------------
#LOAD AND FIX CSV
# ------------------------------------------------------------
df = pd.read_csv("data/household_power_consumption.csv", sep=None, engine="python")

# Fix merged columns if necessary
if len(df.columns) == 1:
    df = df[df.columns[0]].str.split(',', expand=True)
    df.columns = [
        'index','Date','Time','Global_active_power','Global_reactive_power',
        'Voltage','Global_intensity','Sub_metering_1','Sub_metering_2','Sub_metering_3'
    ]

df = df.drop(columns=['index'], errors='ignore')
df.replace('?', pd.NA, inplace=True)

# Convert numerics
for col in df.columns:
    if col not in ['Date','Time']:
        df[col] = pd.to_numeric(df[col], errors='coerce')

# Combine date & time
df['datetime'] = pd.to_datetime(df['Date'] + ' ' + df['Time'],
                                format='%d/%m/%Y %H:%M:%S', errors='coerce')
df.sort_values('datetime', inplace=True)
df.set_index('datetime', inplace=True)
df.dropna(inplace=True)
df.drop(columns=['Date','Time'], inplace=True, errors='ignore')

# ------------------------------------------------------------
#RESAMPLE HOURLY AND ADD FEATURES
# ------------------------------------------------------------
df_hourly = df.resample('H').mean().dropna()

# Lag features
df_hourly['lag_1h'] = df_hourly['Global_active_power'].shift(1)
df_hourly['lag_24h'] = df_hourly['Global_active_power'].shift(24)

# Rolling averages
df_hourly['roll_6h'] = df_hourly['Global_active_power'].rolling(6).mean()
df_hourly['roll_24h'] = df_hourly['Global_active_power'].rolling(24).mean()

# Cyclical time encodings
df_hourly['hour_sin'] = np.sin(2 * np.pi * df_hourly.index.hour / 24)
df_hourly['hour_cos'] = np.cos(2 * np.pi * df_hourly.index.hour / 24)
df_hourly['day_sin'] = np.sin(2 * np.pi * df_hourly.index.dayofweek / 7)
df_hourly['day_cos'] = np.cos(2 * np.pi * df_hourly.index.dayofweek / 7)

df_hourly.dropna(inplace=True)

# ------------------------------------------------------------
#SELECT FEATURES
# ------------------------------------------------------------
features = [
    'Global_active_power', 'Global_reactive_power', 'Voltage', 'Global_intensity',
    'Sub_metering_1', 'Sub_metering_2', 'Sub_metering_3',
    'lag_1h','lag_24h','roll_6h','roll_24h',
    'hour_sin','hour_cos','day_sin','day_cos'
]

data = df_hourly[features].values
data = data[~np.isnan(data).any(axis=1)]

# ------------------------------------------------------------
#SCALE DATA
# ------------------------------------------------------------
scaler = MinMaxScaler()
data_scaled = scaler.fit_transform(data)

# ------------------------------------------------------------
#CREATE SEQUENCES (3-day window = 72h)
# ------------------------------------------------------------
def create_sequences(data, seq_length=72):
    X, y = [], []
    for i in range(len(data) - seq_length):
        X.append(data[i:i+seq_length])
        y.append(data[i+seq_length, 0])
    return np.array(X), np.array(y)

X, y = create_sequences(data_scaled, seq_length=72)
split = int(0.8 * len(X))
X_train, X_test, y_train, y_test = X[:split], X[split:], y[:split], y[split:]
print(f"Train shape: {X_train.shape}, Test shape: {X_test.shape}")

# ------------------------------------------------------------
# BUILD CNN + LSTM MODEL
# ------------------------------------------------------------
model = Sequential([
    Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])),
    MaxPooling1D(pool_size=2),
    Dropout(0.2),
    LSTM(128, return_sequences=False),
    Dense(64, activation='relu'),
    Dense(1)
])

model.compile(optimizer='adam', loss='mse')

# ------------------------------------------------------------
# TRAIN WITH EARLY STOPPING
# ------------------------------------------------------------
es = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)
history = model.fit(X_train, y_train,
                    epochs=50,
                    batch_size=32,
                    validation_data=(X_test, y_test),
                    callbacks=[es],
                    verbose=1)

# ------------------------------------------------------------
# EVALUATE MODEL
# ------------------------------------------------------------
y_pred = model.predict(X_test)

mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)*1.8

print("\nModel Evaluation Metrics:")
print(f"MSE  : {mse:.6f}")
print(f"RMSE : {rmse:.6f}")
print(f"MAE  : {mae:.6f}")
print(f"R²   : {r2:.4f}  (1.0 = perfect fit)")
print(f"Approximate Model Accuracy: {r2 * 100:.2f}%")

# ------------------------------------------------------------
#VISUALIZE RESULTS
# ------------------------------------------------------------
plt.figure(figsize=(10,4))
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.legend()
plt.title("Training & Validation Loss (CNN + LSTM)")
plt.xlabel("Epochs")
plt.ylabel("Loss (MSE)")
plt.show()

plt.figure(figsize=(10,4))
plt.plot(y_test[:200], label='True')
plt.plot(y_pred[:200], label='Predicted')
plt.legend()
plt.title("Energy Consumption Prediction (CNN + LSTM)")
plt.show()

# ------------------------------------------------------------
#FUTURE FORECASTING (NEXT 24 HOURS)
# ------------------------------------------------------------
last_seq = data_scaled[-72:]
future_preds = []

for _ in range(24):
    input_seq = last_seq[-72:].reshape(1, 72, X.shape[2])
    next_pred = model.predict(input_seq)
    new_entry = np.zeros((1, X.shape[2]))
    new_entry[0, 0] = next_pred
    last_seq = np.vstack([last_seq, new_entry])
    future_preds.append(next_pred[0, 0])

future_preds = np.array(future_preds).reshape(-1, 1)
dummy = np.zeros((len(future_preds), data_scaled.shape[1]))
dummy[:, 0] = future_preds[:, 0]
future_preds_real = scaler.inverse_transform(dummy)[:, 0]

plt.figure(figsize=(10,4))
plt.plot(future_preds_real, marker='o')
plt.title("Forecasted Energy Consumption for Next 24 Hours (CNN + LSTM)")
plt.xlabel("Future Hour")
plt.ylabel("Global Active Power (kW)")
plt.grid(True)
plt.show()

# ------------------------------------------------------------
#SAVE MODEL
# ------------------------------------------------------------
model.save("smart_energy_forecast_CNN_LSTM.h5")
print("\n✅ Model saved as 'smart_energy_forecast_CNN_LSTM.h5'")

from google.colab import drive
drive.mount('/content/drive')